---
title: "Minimal Multi-Agent Customer Support System"
company: "Minimal"
author: "Titus Ex and Niek Hogenboom"
source: "https://blog.langchain.com/how-minimal-built-a-multi-agent-customer-support-system-with-langgraph-langsmith/"
date: "2025-01"
category: "productivity"
tags: ["multi-agent", "customer-support", "workflow-automation"]
description: "80%+ efficiency gains with multi-agent system autonomously handling 90% of support tickets"
---

# Minimal Multi-Agent Customer Support System

## The Problem

E-commerce businesses rely on human agents to handle customer support tickets ranging from simple inquiries (T1) to complex order management issues (T2/T3). Each ticket requires researching company policies, customer history, and sometimes executing actions like refunds or address updates.

**The Manual Process:**
- Support agents manually read each incoming ticket
- Search through company knowledge bases for return policies, shipping rules, troubleshooting guides
- Look up customer order history and details
- Manually execute actions in e-commerce platforms (refunds, cancellations, address updates)
- Craft responses following company guidelines and tone
- Each complex ticket can take 15-30 minutes of agent time

**Key Pain Points:**
- Repetitive questions consume valuable agent time that could be spent on complex escalations
- Inconsistent responses when different agents interpret policies differently
- Manual data lookup across multiple systems slows resolution time
- Human error in policy application or order management actions
- Support teams don't scale efficiently with business growth

## The Solution

A multi-agent AI system that automatically processes customer support tickets for e-commerce businesses, generating accurate responses and executing order management actions across integrated platforms like Zendesk, Front, Gorgias, and Shopify.

**Impact**: Achieving 80%+ efficiency gains across e-commerce stores with improved customer satisfaction. The system expects to autonomously handle 90% of customer support tickets, escalating only 10% to human agents.

## How It Works

**Key Capabilities:**
- **Three-Agent Architecture** - Specialized agents for planning, research, and tool execution work collaboratively
- **Knowledge Base Integration** - Automatically retrieves relevant policies, procedures, and guidelines
- **Action Execution** - Directly performs operations like order cancellations, refunds, and address updates
- **Multi-Platform Support** - Integrates with Zendesk, Front, Gorgias (helpdesk) and Shopify, Monta WMS, Firmhouse (e-commerce)

**Process Flow:**
1. Customer ticket arrives through integrated helpdesk platform
2. **Planner Agent** analyzes the query and breaks it into sub-problems (e.g., "Return Policy" + "Order Status Check")
3. **Research Agents** (specialized by sub-problem) search knowledge bases to find relevant policies, shipping rules, or troubleshooting guides
4. Research agents aggregate findings and send back to Planner Agent
5. **Planner Agent** creates a "tool plan" based on research results
6. **Tool-Calling Agent** executes the plan, performing actions like:
   - Looking up order details in Shopify
   - Canceling or refunding orders
   - Updating shipping addresses
   - Applying business rules for refund eligibility
7. System generates draft response or automatically sends reply (depending on co-pilot vs. automated mode)
8. All actions logged with chain-of-thought reasoning for validation

**Technical Architecture:** The multi-agent design uses LangGraph for orchestration, allowing each agent to specialize while maintaining flexible communication patterns. LangSmith provides testing infrastructure with trace logs to catch reasoning errors and refine prompts iteratively.

## Key Insight

**Splitting tasks across specialized agents instead of using a monolithic prompt dramatically improved reliability and reduced costs.** The team discovered that a single large prompt handling planning, research, and tool execution led to conflated tasks, reasoning errors, and expensive token usage.

**Why This Matters:**
- Monolithic prompts struggle to maintain context across multiple reasoning tasks, leading to errors in policy application
- Specialized agents can be independently refined and tested without disrupting the entire system
- Separating research from tool execution creates clear boundaries for validation and safety checks
- Adding new capabilities (like handling a new document type or integrating a new platform) only requires adding new specialized agents rather than rewriting the entire prompt
- LangSmith's testing infrastructure enabled rapid iteration by exposing exactly where reasoning failed in the agent chain

**Development Approach:** The team extensively used LangSmith during development to run side-by-side prompt comparisons (few-shot vs. zero-shot vs. chain-of-thought), track performance over time, and log each sub-agent's output. When they found errors, they created new test cases in trace logs, added few-shot examples, or split sub-problems furtherâ€”all without losing development velocity.

**Scale Achievement:** Already generating revenue from Dutch e-commerce clients, with plans to expand across Europe. The modular architecture makes it straightforward to transition to next-gen LLMs or add new specialized agents as product features expand.

## Links

- [Original Article](https://blog.langchain.com/how-minimal-built-a-multi-agent-customer-support-system-with-langgraph-langsmith/) - Full case study with technical details
- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/) - Multi-agent orchestration framework
- [LangSmith](https://www.langchain.com/langsmith) - Testing and debugging platform used for development
